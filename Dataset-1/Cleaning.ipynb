{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cde07-fcc4-4598-a1fc-571cd773e4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EEG_ROOT = /home/tsultan1/paper-2/dataset-1/BMIS_EEG_DATA/BMIS_EEG_DATA/data/csv_data\n",
      "[INFO] EMG_ROOT = /home/tsultan1/paper-2/dataset-1/BMIS_EMG_DATA/BMIS_EMG_DATA/data/csv_data\n",
      "[INFO] Exporting subject_9 to: /home/tsultan1/paper-2/dataset-1/final_exports-sub9\n",
      "[OK] subject_9: windows=1043\n",
      "\n",
      "[SAVED DATASET-1 SUB-1]\n",
      "  /home/tsultan1/paper-2/dataset-1/final_exports-sub9/eeg_sub9.csv\n",
      "  /home/tsultan1/paper-2/dataset-1/final_exports-sub9/emg_sub9.csv\n",
      "  /home/tsultan1/paper-2/dataset-1/final_exports-sub9/labels_sub9.csv\n",
      "  /home/tsultan1/paper-2/dataset-1/final_exports-sub9/combined_sub9.csv\n",
      "Rows: 1043 | labels: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DATASET-1 (BMIS) — SUB-1 ONLY → FINAL TRAINING CSVs (NO PLOTS)\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, sosfilt, filtfilt, iirnotch, resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (same preprocessing)\n",
    "# ----------------------------\n",
    "SUBJECT_ID = 9\n",
    "NO_GESTURE = 7\n",
    "\n",
    "EMG_FS = 200\n",
    "EEG_FS = 250\n",
    "\n",
    "NOTCH_FREQ = 60\n",
    "QUALITY_FACTOR = 30\n",
    "\n",
    "EMG_FC, EMG_FH = 5, 50\n",
    "EEG_FC, EEG_FH = 5, 50\n",
    "\n",
    "ORDER = 4\n",
    "WINDOW_TIME_MS = 1000\n",
    "OVERLAP_PERCENT = 80\n",
    "TARGET_FS = 200\n",
    "\n",
    "# Dataset-1 roots\n",
    "DATASET1_ROOT = \"/home/tsultan1/paper-2/dataset-1\"\n",
    "EEG_BASE = os.path.join(DATASET1_ROOT, \"BMIS_EEG_DATA\")\n",
    "EMG_BASE = os.path.join(DATASET1_ROOT, \"BMIS_EMG_DATA\")\n",
    "\n",
    "# Output (sub-1 folder)\n",
    "OUT_DIR = os.path.join(DATASET1_ROOT, \"final_exports-sub9\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Expected channels (match dataset design)\n",
    "EXPECTED_EEG_CH = 8\n",
    "EXPECTED_EMG_CH = 8\n",
    "FORCE_FIXED_CHANNELS = True  # prevents dimension errors\n",
    "\n",
    "# ============================================================\n",
    "# Filtering Functions (same logic as old)\n",
    "# ============================================================\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], analog=False, btype='bandpass', output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    data_t = data.T\n",
    "    filtered_t = np.zeros_like(data_t)\n",
    "    for i in range(data_t.shape[0]):\n",
    "        filtered_t[i, :] = sosfilt(sos, data_t[i, :])\n",
    "    return filtered_t.T\n",
    "\n",
    "def mains_removal(data, fs, notch_freq, quality_factor):\n",
    "    b, a = iirnotch(notch_freq, quality_factor, fs)\n",
    "    data_t = data.T\n",
    "    # old behavior used method='gust' (can crash on short/odd signals) → safe fallback\n",
    "    try:\n",
    "        filtered_t = filtfilt(b, a, data_t, axis=1, method='gust')\n",
    "    except Exception:\n",
    "        try:\n",
    "            filtered_t = filtfilt(b, a, data_t, axis=1)\n",
    "        except Exception:\n",
    "            # last resort: return un-notched\n",
    "            filtered_t = data_t\n",
    "    return filtered_t.T\n",
    "\n",
    "def preprocess_data(data, fs, notch_freq, quality_factor, lowcut, highcut, order, target_fs=None):\n",
    "    notched_data = mains_removal(data, fs=fs, notch_freq=notch_freq, quality_factor=quality_factor)\n",
    "    filtered_data = butter_bandpass_filter(notched_data, lowcut=lowcut, highcut=highcut, fs=fs, order=order)\n",
    "\n",
    "    # Downsample if target_fs is provided\n",
    "    if target_fs and fs != target_fs:\n",
    "        num_samples = int(data.shape[1] * target_fs / fs)\n",
    "        filtered_data = resample(filtered_data, num=num_samples, axis=1)\n",
    "    return filtered_data\n",
    "\n",
    "# ============================================================\n",
    "# Windowing Function (same behavior; plus safe guards)\n",
    "# ============================================================\n",
    "\n",
    "def window_with_overlap(data, sampling_frequency, window_time, overlap, no_channel):\n",
    "    samples_per_window = int(sampling_frequency * (window_time / 1000))\n",
    "    step_size = int(samples_per_window * (1 - overlap / 100))\n",
    "    step_size = max(step_size, 1)\n",
    "\n",
    "    if data.shape[1] < samples_per_window:\n",
    "        return np.zeros((0, no_channel, samples_per_window), dtype=data.dtype)\n",
    "\n",
    "    num_windows = (data.shape[1] - samples_per_window) // step_size + 1\n",
    "    if num_windows <= 0:\n",
    "        return np.zeros((0, no_channel, samples_per_window), dtype=data.dtype)\n",
    "\n",
    "    windows = np.zeros((num_windows, no_channel, samples_per_window), dtype=data.dtype)\n",
    "    for i in range(num_windows):\n",
    "        start = i * step_size\n",
    "        end = start + samples_per_window\n",
    "        windows[i] = data[:, start:end]\n",
    "    return windows\n",
    "\n",
    "def truncate_to_min_length(data1, data2):\n",
    "    min_length = min(data1.shape[1], data2.shape[1])\n",
    "    return data1[:, :min_length], data2[:, :min_length]\n",
    "\n",
    "# ============================================================\n",
    "# Robust subject/gesture file discovery\n",
    "# ============================================================\n",
    "\n",
    "_SUBJ_RE = re.compile(r\"subject_(\\d+)$\", re.IGNORECASE)\n",
    "\n",
    "def find_subject_root(base_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds directory that directly contains subject_1, subject_2, ...\n",
    "    Searches recursively in case files are nested.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {base_dir}\")\n",
    "\n",
    "    # direct hit\n",
    "    for name in os.listdir(base_dir):\n",
    "        if _SUBJ_RE.match(name) and os.path.isdir(os.path.join(base_dir, name)):\n",
    "            return base_dir\n",
    "\n",
    "    # recursive search\n",
    "    for root, dirs, _ in os.walk(base_dir):\n",
    "        for d in dirs:\n",
    "            if _SUBJ_RE.match(d):\n",
    "                return root\n",
    "\n",
    "    raise RuntimeError(f\"Could not find any subject_* folders under: {base_dir}\")\n",
    "\n",
    "EEG_ROOT = find_subject_root(EEG_BASE)\n",
    "EMG_ROOT = find_subject_root(EMG_BASE)\n",
    "\n",
    "def files_for_subject_gesture(root_dir: str, subject_id: int, gesture_idx_1based: int):\n",
    "    subj_dir = os.path.join(root_dir, f\"subject_{subject_id}\")\n",
    "    if not os.path.isdir(subj_dir):\n",
    "        return []\n",
    "    pat = re.compile(rf\"G{gesture_idx_1based}\", re.IGNORECASE)\n",
    "    out = []\n",
    "    for f in os.listdir(subj_dir):\n",
    "        if f.lower().endswith(\".csv\") and pat.search(f):\n",
    "            out.append(os.path.join(subj_dir, f))\n",
    "    return sorted(out)\n",
    "\n",
    "# ============================================================\n",
    "# Robust CSV loading + channel fixing (prevents dimension errors)\n",
    "# ============================================================\n",
    "\n",
    "def _read_csv_numeric(filepath: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read CSV, keep numeric content only.\n",
    "    Removes non-numeric columns and replaces NaNs/infs with 0.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    arr = df.to_numpy(dtype=np.float64, copy=False)\n",
    "    arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(1, -1)\n",
    "    return arr\n",
    "\n",
    "def _pick_best_channels(x: np.ndarray, expected_ch: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    If too many channels, drop the most 'time/index-like' ones first.\n",
    "    Fallback: keep first expected_ch.\n",
    "    \"\"\"\n",
    "    ch, t = x.shape\n",
    "    if ch <= expected_ch:\n",
    "        return x\n",
    "\n",
    "    ramp = np.linspace(-1.0, 1.0, t, dtype=np.float64)\n",
    "    scores = []\n",
    "    for i in range(ch):\n",
    "        v = x[i].astype(np.float64, copy=False)\n",
    "        if np.std(v) < 1e-12:\n",
    "            corr = 1.0\n",
    "        else:\n",
    "            corr = float(np.corrcoef(v, ramp)[0, 1])\n",
    "            corr = abs(corr) if np.isfinite(corr) else 1.0\n",
    "        var_pen = 1.0 / (np.std(v) + 1e-12)\n",
    "        scores.append(corr + 0.01 * var_pen)\n",
    "\n",
    "    keep_idx = np.argsort(np.asarray(scores))[:expected_ch]\n",
    "    keep_idx = np.sort(keep_idx)\n",
    "    return x[keep_idx, :]\n",
    "\n",
    "def ensure_channels_by_time(arr: np.ndarray, expected_ch: int, force_fixed: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return array shaped (expected_ch, time). Handles orientation mismatch.\n",
    "    \"\"\"\n",
    "    if arr.shape[0] == expected_ch:\n",
    "        x = arr\n",
    "    elif arr.shape[1] == expected_ch:\n",
    "        x = arr.T\n",
    "    else:\n",
    "        # choose orientation where channels dimension is closer to expected_ch\n",
    "        if abs(arr.shape[0] - expected_ch) > abs(arr.shape[1] - expected_ch):\n",
    "            x = arr.T\n",
    "        else:\n",
    "            x = arr\n",
    "\n",
    "    if x.ndim != 2:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "    ch, t = x.shape\n",
    "    if ch != expected_ch:\n",
    "        if not force_fixed:\n",
    "            raise ValueError(f\"Channel mismatch: got {ch}, expected {expected_ch}\")\n",
    "\n",
    "        if ch > expected_ch:\n",
    "            x = _pick_best_channels(x, expected_ch)\n",
    "        else:\n",
    "            pad = np.zeros((expected_ch - ch, t), dtype=x.dtype)\n",
    "            x = np.vstack([x, pad])\n",
    "    return x\n",
    "\n",
    "def stack_trials_timewise(file_list, expected_ch: int, force_fixed: bool, transpose: bool):\n",
    "    \"\"\"\n",
    "    Load each trial, enforce (ch,time), then concatenate timewise (axis=1),\n",
    "    matching your old np.column_stack behavior.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for fp in file_list:\n",
    "        try:\n",
    "            arr = _read_csv_numeric(fp)\n",
    "            if transpose:\n",
    "                arr = arr.T\n",
    "            arr = ensure_channels_by_time(arr, expected_ch, force_fixed)\n",
    "            if arr.shape[1] > 0:\n",
    "                chunks.append(arr)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Skipping file: {fp} | reason: {e}\")\n",
    "            continue\n",
    "    if not chunks:\n",
    "        return None\n",
    "    return np.column_stack(chunks)\n",
    "\n",
    "# ============================================================\n",
    "# Subject pipeline (SUB-1)\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_subject(subject_id: int):\n",
    "    X_emg_list, X_eeg_list, y_list, subj_list = [], [], [], []\n",
    "    total_windows = 0\n",
    "\n",
    "    for g0 in range(NO_GESTURE):      # labels 0..6\n",
    "        g1 = g0 + 1                   # file pattern G1..G7\n",
    "\n",
    "        # IMPORTANT: keep old orientation logic\n",
    "        #   EMG: transpose=False\n",
    "        #   EEG: transpose=True\n",
    "        emg_files = files_for_subject_gesture(EMG_ROOT, subject_id, g1)\n",
    "        eeg_files = files_for_subject_gesture(EEG_ROOT, subject_id, g1)\n",
    "        if not emg_files or not eeg_files:\n",
    "            continue\n",
    "\n",
    "        emg_raw = stack_trials_timewise(emg_files, EXPECTED_EMG_CH, FORCE_FIXED_CHANNELS, transpose=False)\n",
    "        eeg_raw = stack_trials_timewise(eeg_files, EXPECTED_EEG_CH, FORCE_FIXED_CHANNELS, transpose=True)\n",
    "        if emg_raw is None or eeg_raw is None:\n",
    "            continue\n",
    "\n",
    "        # preprocessing (same)\n",
    "        emg_pp = preprocess_data(emg_raw, EMG_FS, NOTCH_FREQ, QUALITY_FACTOR, EMG_FC, EMG_FH, ORDER, TARGET_FS)\n",
    "        eeg_pp = preprocess_data(eeg_raw, EEG_FS, NOTCH_FREQ, QUALITY_FACTOR, EEG_FC, EEG_FH, ORDER, TARGET_FS)\n",
    "\n",
    "        # truncate to common length (same)\n",
    "        emg_pp, eeg_pp = truncate_to_min_length(emg_pp, eeg_pp)\n",
    "\n",
    "        # window (same)\n",
    "        emg_w = window_with_overlap(emg_pp, TARGET_FS, WINDOW_TIME_MS, OVERLAP_PERCENT, emg_pp.shape[0])\n",
    "        eeg_w = window_with_overlap(eeg_pp, TARGET_FS, WINDOW_TIME_MS, OVERLAP_PERCENT, eeg_pp.shape[0])\n",
    "        if emg_w.shape[0] == 0 or eeg_w.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # align window counts (same logic)\n",
    "        n = min(emg_w.shape[0], eeg_w.shape[0])\n",
    "        emg_w = emg_w[:n].astype(np.float32)\n",
    "        eeg_w = eeg_w[:n].astype(np.float32)\n",
    "\n",
    "        X_emg_list.append(emg_w)\n",
    "        X_eeg_list.append(eeg_w)\n",
    "        y_list.extend([g0] * n)\n",
    "        subj_list.extend([subject_id] * n)\n",
    "        total_windows += n\n",
    "\n",
    "    if not X_emg_list or not X_eeg_list:\n",
    "        raise RuntimeError(f\"No windows produced for subject_{subject_id}. Check subject folder / filenames G1..G7.\")\n",
    "\n",
    "    X_emg = np.vstack(X_emg_list)   # (N, ch, T)\n",
    "    X_eeg = np.vstack(X_eeg_list)   # (N, ch, T)\n",
    "    y = np.asarray(y_list, dtype=np.int64)\n",
    "    subj = np.asarray(subj_list, dtype=np.int64)\n",
    "\n",
    "    # safety clip\n",
    "    n = min(len(y), len(subj), X_emg.shape[0], X_eeg.shape[0])\n",
    "    return X_emg[:n], X_eeg[:n], y[:n], subj[:n], total_windows\n",
    "\n",
    "def export_subject_csvs(X_emg, X_eeg, y, subj, out_dir: str, subject_id: int):\n",
    "    # flatten like old code\n",
    "    Xeeg_2d = X_eeg.reshape(X_eeg.shape[0], -1)\n",
    "    Xemg_2d = X_emg.reshape(X_emg.shape[0], -1)\n",
    "\n",
    "    # MinMaxScaler (same idea as old)\n",
    "    eeg_scaler = MinMaxScaler()\n",
    "    emg_scaler = MinMaxScaler()\n",
    "    Xeeg_norm = eeg_scaler.fit_transform(Xeeg_2d).astype(np.float32)\n",
    "    Xemg_norm = emg_scaler.fit_transform(Xemg_2d).astype(np.float32)\n",
    "\n",
    "    # export file paths (same naming style as dataset-2 exports)\n",
    "    eeg_path = os.path.join(out_dir, f\"eeg_sub{subject_id}.csv\")\n",
    "    emg_path = os.path.join(out_dir, f\"emg_sub{subject_id}.csv\")\n",
    "    lab_path = os.path.join(out_dir, f\"labels_sub{subject_id}.csv\")\n",
    "    comb_path = os.path.join(out_dir, f\"combined_sub{subject_id}.csv\")\n",
    "\n",
    "    # save EEG/EMG as numeric-only matrices (no extra cols)\n",
    "    pd.DataFrame(Xeeg_norm).to_csv(eeg_path, index=False)\n",
    "    pd.DataFrame(Xemg_norm).to_csv(emg_path, index=False)\n",
    "\n",
    "    # labels (subject_id + Label)\n",
    "    pd.DataFrame({\"subject_id\": subj, \"Label\": y}).to_csv(lab_path, index=False)\n",
    "\n",
    "    # combined (subject_id, Label, eeg_*, emg_*)\n",
    "    eeg_cols = [f\"eeg_{i}\" for i in range(Xeeg_norm.shape[1])]\n",
    "    emg_cols = [f\"emg_{i}\" for i in range(Xemg_norm.shape[1])]\n",
    "\n",
    "    df_eeg = pd.DataFrame(Xeeg_norm, columns=eeg_cols)\n",
    "    df_emg = pd.DataFrame(Xemg_norm, columns=emg_cols)\n",
    "\n",
    "    df_eeg.insert(0, \"Label\", y)\n",
    "    df_eeg.insert(0, \"subject_id\", subj)\n",
    "\n",
    "    df_comb = pd.concat([df_eeg, df_emg], axis=1)\n",
    "    df_comb.to_csv(comb_path, index=False)\n",
    "\n",
    "    print(\"\\n[SAVED DATASET-1 SUB-1]\")\n",
    "    print(\" \", eeg_path)\n",
    "    print(\" \", emg_path)\n",
    "    print(\" \", lab_path)\n",
    "    print(\" \", comb_path)\n",
    "    print(f\"Rows: {len(y)} | labels: {np.unique(y)}\")\n",
    "    return eeg_path, emg_path, lab_path, comb_path\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"[INFO] EEG_ROOT = {EEG_ROOT}\")\n",
    "    print(f\"[INFO] EMG_ROOT = {EMG_ROOT}\")\n",
    "    print(f\"[INFO] Exporting subject_{SUBJECT_ID} to: {OUT_DIR}\")\n",
    "\n",
    "    X_emg, X_eeg, y, subj, total = preprocess_subject(SUBJECT_ID)\n",
    "    print(f\"[OK] subject_{SUBJECT_ID}: windows={total}\")\n",
    "\n",
    "    export_subject_csvs(X_emg, X_eeg, y, subj, OUT_DIR, SUBJECT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071384f-6f88-450c-b28d-7f697322b314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
