{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af84a8-225d-4835-94b1-ba657d4efcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET-1 (BMIS) â€” ALL SUBJECTS (sub1..sub33) COMBINED TRAINING\n",
    "\n",
    "#\n",
    "# Expected per-subject folder layout:\n",
    "#   /home/tsultan1/paper-2/dataset-1/final_exports-sub{K}/\n",
    "#       eeg_sub{K}.csv\n",
    "#       emg_sub{K}.csv\n",
    "#       labels_sub{K}.csv   (columns: subject_id, Label)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score,\n",
    "    confusion_matrix, balanced_accuracy_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, log_loss,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from scipy.signal import correlate, resample\n",
    "from sklearn.metrics import hamming_loss, top_k_accuracy_score\n",
    "\n",
    "# -----------------------------\n",
    "# GPU\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[DEVICE] {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Root + subject range\n",
    "# -----------------------------\n",
    "ROOT = \"/home/tsultan1/paper-2/dataset-1\"\n",
    "SUBJECT_MAX = 33\n",
    "\n",
    "# -----------------------------\n",
    "# Robust CSV read (numeric only)\n",
    "# -----------------------------\n",
    "def read_numeric_csv(path: str) -> np.ndarray:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "    return df.to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "def read_labels_csv(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Label\" not in df.columns:\n",
    "        raise ValueError(f\"'Label' column not found in {path}. Columns={list(df.columns)}\")\n",
    "    # keep numeric Label\n",
    "    df[\"Label\"] = pd.to_numeric(df[\"Label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    if \"subject_id\" in df.columns:\n",
    "        df[\"subject_id\"] = pd.to_numeric(df[\"subject_id\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    else:\n",
    "        df[\"subject_id\"] = -1\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# Sliding Window Cross-Correlation (same logic)\n",
    "# -----------------------------\n",
    "def sliding_window_cross_correlation(eeg, emg, window_size=100, overlap=50):\n",
    "    eeg_aligned = np.zeros_like(eeg)\n",
    "    emg_aligned = np.zeros_like(emg)\n",
    "    step = window_size - overlap\n",
    "    sync_scores = []\n",
    "\n",
    "    if len(eeg) < window_size or len(emg) < window_size:\n",
    "        return eeg, emg, 0.0\n",
    "\n",
    "    for i in range(0, len(eeg) - window_size, step):\n",
    "        eeg_window = eeg[i:i + window_size].flatten()\n",
    "        emg_window = emg[i:i + window_size].flatten()\n",
    "\n",
    "        eeg_std = np.std(eeg_window)\n",
    "        emg_std = np.std(emg_window)\n",
    "        if eeg_std < 1e-12 or emg_std < 1e-12:\n",
    "            eeg_aligned[i:i + window_size] = eeg[i:i + window_size]\n",
    "            emg_aligned[i:i + window_size] = emg[i:i + window_size]\n",
    "            sync_scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        eeg_window = (eeg_window - np.mean(eeg_window)) / eeg_std\n",
    "        emg_window = (emg_window - np.mean(emg_window)) / emg_std\n",
    "\n",
    "        correlation = correlate(eeg_window, emg_window, mode=\"full\")\n",
    "        lags = np.arange(-len(eeg_window) + 1, len(emg_window))\n",
    "\n",
    "        denom = (np.linalg.norm(eeg_window) * np.linalg.norm(emg_window))\n",
    "        if denom < 1e-12:\n",
    "            correlation = np.zeros_like(correlation)\n",
    "        else:\n",
    "            correlation = correlation / denom\n",
    "\n",
    "        lag = lags[np.argmax(correlation)]\n",
    "        max_corr = float(np.max(correlation))\n",
    "        sync_scores.append(max_corr)\n",
    "\n",
    "        if lag > 0:\n",
    "            eeg_aligned[i:i + window_size] = np.roll(eeg[i:i + window_size], lag, axis=0)\n",
    "            emg_aligned[i:i + window_size] = emg[i:i + window_size]\n",
    "        else:\n",
    "            eeg_aligned[i:i + window_size] = eeg[i:i + window_size]\n",
    "            emg_aligned[i:i + window_size] = np.roll(emg[i:i + window_size], -lag, axis=0)\n",
    "\n",
    "    avg_sync_score = float(np.mean(sync_scores)) if len(sync_scores) else 0.0\n",
    "    return eeg_aligned, emg_aligned, avg_sync_score\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class EEGEMGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL (UNCHANGED)\n",
    "# -----------------------------\n",
    "class EEGEMGTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_classes, dropout_rate=0.5):\n",
    "        super(EEGEMGTransformer, self).__init__()\n",
    "        self.align_eeg = nn.Linear(input_dim, input_dim)\n",
    "        self.align_emg = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        self.eeg_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True, dropout=dropout_rate),\n",
    "            num_layers=2\n",
    "        )\n",
    "        self.emg_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True, dropout=dropout_rate),\n",
    "            num_layers=2\n",
    "        )\n",
    "\n",
    "        self.eeg_projector = nn.Linear(input_dim, hidden_dim)\n",
    "        self.emg_projector = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.cross_attention_weights = nn.Parameter(torch.tensor([[0.7], [0.3]]), requires_grad=True)\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, eeg, emg):\n",
    "        eeg = self.align_eeg(eeg)\n",
    "        emg = self.align_emg(emg)\n",
    "\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "\n",
    "        eeg_features = self.eeg_projector(eeg_features)\n",
    "        emg_features = self.emg_projector(emg_features)\n",
    "\n",
    "        eeg_features = self.dropout(eeg_features)\n",
    "        emg_features = self.dropout(emg_features)\n",
    "\n",
    "        combined_features = (\n",
    "            self.cross_attention_weights[0] * eeg_features + self.cross_attention_weights[1] * emg_features\n",
    "        )\n",
    "        combined, _ = self.cross_attention(combined_features, combined_features, combined_features)\n",
    "        output = self.fc(combined.mean(dim=1))\n",
    "        return output, self.cross_attention_weights\n",
    "\n",
    "# -----------------------------\n",
    "# Online adaptation (same behavior) + GPU\n",
    "# -----------------------------\n",
    "def online_adaptation_with_regularization(\n",
    "    model, optimizer, buffer_X, buffer_y, criterion, val_loader, num_cycles=2, batch_size=8, lr=0.00001\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    # uses X_train/y_train from outer scope (same as your pattern)\n",
    "    replay_buffer_X = X_train[:100]\n",
    "    replay_buffer_y = y_train[:100]\n",
    "    buffer_X = np.concatenate([buffer_X, replay_buffer_X], axis=0)\n",
    "    buffer_y = np.concatenate([buffer_y, replay_buffer_y], axis=0)\n",
    "\n",
    "    buffer_dataset = EEGEMGDataset(buffer_X, buffer_y)\n",
    "    buffer_loader = DataLoader(buffer_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "        optimizer, base_lr=lr/10, max_lr=lr, step_size_up=5, mode=\"triangular2\"\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    for _cycle in range(num_cycles):\n",
    "        for X_batch, y_batch in buffer_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            eeg = X_batch[:, :input_dim].unsqueeze(1)\n",
    "            emg = X_batch[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(eeg, emg)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                eeg = X_batch[:, :input_dim].unsqueeze(1)\n",
    "                emg = X_batch[:, input_dim:].unsqueeze(1)\n",
    "                outputs, _ = model(eeg, emg)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "\n",
    "        val_loss /= max(len(val_loader), 1)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics (NO plots)\n",
    "# -----------------------------\n",
    "def calculate_hamming_loss(y_true, y_pred):\n",
    "    return hamming_loss(y_true, y_pred)\n",
    "\n",
    "def calculate_top_k_accuracy(y_true, y_scores, k=3):\n",
    "    k = min(k, y_scores.shape[1])\n",
    "    return top_k_accuracy_score(y_true, y_scores, k=k)\n",
    "\n",
    "def evaluate_model(model, val_loader, sync_score_global):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_scores = [], [], []\n",
    "    attention_weights = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            eeg = X_batch[:, :input_dim].unsqueeze(1)\n",
    "            emg = X_batch[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            outputs, weights = model(eeg, emg)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_scores.extend(probs.cpu().numpy())\n",
    "            attention_weights.append(weights.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_scores = np.array(y_scores)\n",
    "    attention_weights = np.array(attention_weights)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred) if len(np.unique(y_true)) > 1 else 0.0\n",
    "\n",
    "    try:\n",
    "        log_loss_value = log_loss(y_true, y_scores, labels=np.arange(y_scores.shape[1]))\n",
    "    except Exception:\n",
    "        log_loss_value = None\n",
    "\n",
    "    hamming_loss_value = calculate_hamming_loss(y_true, y_pred)\n",
    "\n",
    "    try:\n",
    "        top_k_accuracy_value = calculate_top_k_accuracy(y_true, y_scores, k=3)\n",
    "    except Exception:\n",
    "        top_k_accuracy_value = None\n",
    "\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_true, y_scores, multi_class=\"ovr\", average=\"weighted\")\n",
    "        auprc = average_precision_score(y_true, y_scores, average=\"weighted\")\n",
    "    except Exception:\n",
    "        auroc, auprc = None, None\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        per_class_acc = np.diag(cm) / cm.sum(axis=1)\n",
    "        per_class_error = 1 - per_class_acc\n",
    "        per_class_error = per_class_error[np.isfinite(per_class_error)]\n",
    "        mpce = float(np.mean(per_class_error)) if len(per_class_error) else 0.0\n",
    "\n",
    "    try:\n",
    "        avg_attention_weights = np.mean(attention_weights, axis=0)\n",
    "    except Exception:\n",
    "        avg_attention_weights = None\n",
    "\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | Acc: {acc:.4f}\")\n",
    "    print(f\"Balanced Acc: {balanced_acc:.4f} | Kappa: {kappa:.4f} | MCC: {mcc:.4f}\")\n",
    "    if log_loss_value is not None:\n",
    "        print(f\"LogLoss: {log_loss_value:.6f}\")\n",
    "    if auroc is not None:\n",
    "        print(f\"AUROC: {auroc:.4f} | AUPRC: {auprc:.4f}\")\n",
    "    print(f\"MPCE: {mpce:.6f} | Hamming: {hamming_loss_value:.6f}\")\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": balanced_acc,\n",
    "        \"cohen_kappa\": kappa,\n",
    "        \"mcc\": mcc,\n",
    "        \"log_loss\": log_loss_value,\n",
    "        \"auroc\": auroc,\n",
    "        \"auprc\": auprc,\n",
    "        \"mpce\": mpce,\n",
    "        \"hamming_loss\": hamming_loss_value,\n",
    "        \"top_k_accuracy\": top_k_accuracy_value,\n",
    "        \"sync_score\": sync_score_global,\n",
    "        \"attention_weights\": avg_attention_weights,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Training (KEEP your current settings here)\n",
    "# -----------------------------\n",
    "def train_model_with_weight_decay(model, train_loader, val_loader, criterion, epochs=30, patience=5, lr=0.00005):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            eeg = X_batch[:, :input_dim].unsqueeze(1)\n",
    "            emg = X_batch[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(eeg, emg)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                eeg = X_batch[:, :input_dim].unsqueeze(1)\n",
    "                emg = X_batch[:, input_dim:].unsqueeze(1)\n",
    "                outputs, _ = model(eeg, emg)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "\n",
    "        val_loss /= max(len(val_loader), 1)\n",
    "        train_loss = total_loss / max(len(train_loader), 1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD + ALIGN ALL SUBJECTS (SKIP MISSING)\n",
    "# ============================================================\n",
    "combined_list = []\n",
    "labels_list = []\n",
    "subid_list = []\n",
    "sync_scores = []\n",
    "\n",
    "expected_eeg_dim = None\n",
    "expected_emg_dim = None\n",
    "\n",
    "loaded_subjects = []\n",
    "skipped_subjects = []\n",
    "\n",
    "for sid in range(1, SUBJECT_MAX + 1):\n",
    "    sub_dir = os.path.join(ROOT, f\"final_exports-sub{sid}\")\n",
    "    eeg_path = os.path.join(sub_dir, f\"eeg_sub{sid}.csv\")\n",
    "    emg_path = os.path.join(sub_dir, f\"emg_sub{sid}.csv\")\n",
    "    lab_path = os.path.join(sub_dir, f\"labels_sub{sid}.csv\")\n",
    "\n",
    "    if not (os.path.isdir(sub_dir) and os.path.exists(eeg_path) and os.path.exists(emg_path) and os.path.exists(lab_path)):\n",
    "        skipped_subjects.append(sid)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        eeg = read_numeric_csv(eeg_path)\n",
    "        emg = read_numeric_csv(emg_path)\n",
    "        lab_df = read_labels_csv(lab_path)\n",
    "\n",
    "        # Make lengths match (keep the same behavior idea; if mismatch, resample EEG rows)\n",
    "        n = min(len(eeg), len(emg), len(lab_df))\n",
    "        eeg = eeg[:n]\n",
    "        emg = emg[:n]\n",
    "        lab_df = lab_df.iloc[:n].reset_index(drop=True)\n",
    "\n",
    "        # if still mismatch between eeg/emg, resample eeg to match emg (rare)\n",
    "        if len(eeg) != len(emg):\n",
    "            eeg = resample(eeg, num=len(emg), axis=0).astype(np.float32, copy=False)\n",
    "            n2 = min(len(eeg), len(emg), len(lab_df))\n",
    "            eeg, emg = eeg[:n2], emg[:n2]\n",
    "            lab_df = lab_df.iloc[:n2].reset_index(drop=True)\n",
    "\n",
    "        # Check consistent feature dims across subjects (avoid dimension errors)\n",
    "        if expected_eeg_dim is None:\n",
    "            expected_eeg_dim = eeg.shape[1]\n",
    "            expected_emg_dim = emg.shape[1]\n",
    "        else:\n",
    "            if eeg.shape[1] != expected_eeg_dim or emg.shape[1] != expected_emg_dim:\n",
    "                print(f\"[SKIP sub{sid}] dim mismatch: eeg {eeg.shape[1]} vs {expected_eeg_dim} OR emg {emg.shape[1]} vs {expected_emg_dim}\")\n",
    "                skipped_subjects.append(sid)\n",
    "                continue\n",
    "\n",
    "        # Align per subject (important: do NOT align across subject boundaries)\n",
    "        eeg_aligned, emg_aligned, ss = sliding_window_cross_correlation(eeg, emg, window_size=100, overlap=50)\n",
    "        sync_scores.append((ss, len(eeg_aligned)))\n",
    "\n",
    "        combined = np.concatenate([eeg_aligned, emg_aligned], axis=1)  # (n, eeg+emg)\n",
    "        y = lab_df[\"Label\"].to_numpy(dtype=int)\n",
    "        subj_ids = lab_df[\"subject_id\"].to_numpy(dtype=int)\n",
    "\n",
    "        combined_list.append(combined)\n",
    "        labels_list.append(y)\n",
    "        subid_list.append(subj_ids)\n",
    "\n",
    "        loaded_subjects.append(sid)\n",
    "        print(f\"[LOAD OK] sub{sid}: N={len(combined)} | eeg_dim={eeg.shape[1]} | emg_dim={emg.shape[1]} | sync={ss:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP sub{sid}] error: {e}\")\n",
    "        skipped_subjects.append(sid)\n",
    "\n",
    "if not combined_list:\n",
    "    raise RuntimeError(\"No subjects loaded. Check folder names and file paths.\")\n",
    "\n",
    "combined_data = np.concatenate(combined_list, axis=0)\n",
    "labels_raw = np.concatenate(labels_list, axis=0)\n",
    "subject_ids_all = np.concatenate(subid_list, axis=0)\n",
    "\n",
    "# Label encoding (same as before)\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels_raw.ravel())\n",
    "\n",
    "# Weighted avg sync score across subjects (by rows)\n",
    "if sync_scores:\n",
    "    sync_score_global = float(np.sum([s * n for (s, n) in sync_scores]) / np.sum([n for (_, n) in sync_scores]))\n",
    "else:\n",
    "    sync_score_global = 0.0\n",
    "\n",
    "print(\"\\n========== DATA SUMMARY ==========\")\n",
    "print(f\"Loaded subjects: {len(loaded_subjects)} -> {loaded_subjects}\")\n",
    "print(f\"Skipped subjects: {len(skipped_subjects)} -> {skipped_subjects}\")\n",
    "print(f\"Total pooled rows: {combined_data.shape[0]}\")\n",
    "print(f\"Total feature dim: {combined_data.shape[1]}\")\n",
    "print(f\"Global sync score (weighted): {sync_score_global:.6f}\")\n",
    "print(\"Label distribution (encoded):\", dict(zip(*np.unique(labels, return_counts=True))))\n",
    "\n",
    "# ============================================================\n",
    "# K-FOLD TRAINING ON POOLED DATA (NOT LOSO)\n",
    "# ============================================================\n",
    "N = combined_data.shape[0]\n",
    "if N < 2:\n",
    "    raise RuntimeError(f\"Not enough samples to train. Found N={N} pooled rows.\")\n",
    "\n",
    "k = 5\n",
    "k = min(k, N)\n",
    "if k < 2:\n",
    "    raise RuntimeError(f\"Not enough samples for KFold. Need at least 2; found N={N}.\")\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "before_adaptation_metrics = []\n",
    "after_adaptation_metrics = []\n",
    "online_adaptation_percentage = 0.3\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(combined_data), start=1):\n",
    "    print(f\"\\n========== Fold {fold}/{k} ==========\")\n",
    "\n",
    "    X_train = combined_data[train_index]\n",
    "    X_val = combined_data[val_index]\n",
    "    y_train = labels[train_index]\n",
    "    y_val = labels[val_index]\n",
    "\n",
    "    train_dataset = EEGEMGDataset(X_train, y_train)\n",
    "    val_dataset = EEGEMGDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=(device.type == \"cuda\"))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=(device.type == \"cuda\"))\n",
    "\n",
    "    input_dim = X_train.shape[1] // 2\n",
    "    hidden_dim = 256\n",
    "    num_heads = 4\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    model = EEGEMGTransformer(\n",
    "        input_dim=input_dim, hidden_dim=hidden_dim, num_heads=num_heads, num_classes=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train\n",
    "    train_model_with_weight_decay(model, train_loader, val_loader, criterion)\n",
    "\n",
    "    print(\"[EVAL] Before Online Adaptation\")\n",
    "    metrics_before = evaluate_model(model, val_loader, sync_score_global)\n",
    "    before_adaptation_metrics.append(metrics_before)\n",
    "\n",
    "    # Online adaptation (same idea)\n",
    "    online_data_size = int(len(X_val) * online_adaptation_percentage)\n",
    "    online_X = X_val[:online_data_size]\n",
    "    online_y = y_val[:online_data_size]\n",
    "\n",
    "    if online_data_size > 0:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.000001, weight_decay=0.01)\n",
    "        online_adaptation_with_regularization(\n",
    "            model, optimizer, online_X, online_y, criterion, val_loader,\n",
    "            num_cycles=5, batch_size=16, lr=0.00001\n",
    "        )\n",
    "\n",
    "    print(\"[EVAL] After Online Adaptation\")\n",
    "    metrics_after = evaluate_model(model, val_loader, sync_score_global)\n",
    "    after_adaptation_metrics.append(metrics_after)\n",
    "\n",
    "    fold_results.append({\"before_adaptation\": metrics_before, \"after_adaptation\": metrics_after})\n",
    "\n",
    "# Save best model (keeps your same saving style)\n",
    "best_model_index = int(np.argmax([r[\"after_adaptation\"][\"accuracy\"] for r in fold_results]))\n",
    "torch.save(model.state_dict(), \"EEGEMGTransformer_best.pth\")\n",
    "print(f\"\\n[OK] Best model (by AFTER accuracy): Fold {best_model_index+1} saved as EEGEMGTransformer_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e1212-138d-460a-8c2f-d3213199c492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e654fc-70d2-453b-be55-100b70b42396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
