{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe49978-c69a-4e0d-94d4-f56c926d6f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] subject_11: windows=1106\n",
      "\n",
      "[SAVED SUB-1]\n",
      "  /home/tsultan1/paper-2/Dataset-2/final_exports-sub11/eeg_sub1.csv\n",
      "  /home/tsultan1/paper-2/Dataset-2/final_exports-sub11/emg_sub1.csv\n",
      "  /home/tsultan1/paper-2/Dataset-2/final_exports-sub11/labels_sub1.csv\n",
      "  /home/tsultan1/paper-2/Dataset-2/final_exports-sub11/combined_sub1.csv\n",
      "\n",
      "Rows: 1106 | label set: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Sub-1 ONLY (subject_1) â€” robust, no dimension errors\n",
    "# Keeps your published cleaning/filtering/window settings SAME\n",
    "# Exports: eeg_sub1.csv, emg_sub1.csv, labels_sub1.csv, combined_sub1.csv\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter, sosfilt, filtfilt, iirnotch, resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (published settings)\n",
    "# ----------------------------\n",
    "SUBJECT_ID = 11\n",
    "NO_GESTURE = 7\n",
    "\n",
    "EMG_FS = 200\n",
    "EEG_FS = 250\n",
    "\n",
    "NOTCH_FREQ = 60\n",
    "QUALITY_FACTOR = 30\n",
    "\n",
    "EMG_FC, EMG_FH = 5, 50\n",
    "EEG_FC, EEG_FH = 5, 50\n",
    "\n",
    "ORDER = 4\n",
    "WINDOW_TIME_MS = 1000\n",
    "OVERLAP_PERCENT = 80\n",
    "TARGET_FS = 200\n",
    "\n",
    "EEG_BASE = \"/home/tsultan1/paper-2/Dataset-2/EEG_DATA/EEG_DATA/data\"\n",
    "EMG_BASE = \"/home/tsultan1/paper-2/Dataset-2/EMG_DATA/EMG_DATA/data\"\n",
    "\n",
    "OUT_DIR = \"/home/tsultan1/paper-2/Dataset-2/final_exports-sub11\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "EXPECTED_EEG_CH = 8\n",
    "EXPECTED_EMG_CH = 8\n",
    "FORCE_FIXED_CHANNELS = True     # prevents crashes due to odd channel counts\n",
    "DO_AUGMENT = False              # keep False for published-style exports\n",
    "\n",
    "# ============================================================\n",
    "# YOUR ORIGINAL FILTERING FUNCTIONS (kept same)\n",
    "# ============================================================\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], analog=False, btype=\"bandpass\", output=\"sos\")\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    data_t = data.T\n",
    "    filtered_t = np.zeros_like(data_t)\n",
    "    for i in range(data_t.shape[0]):\n",
    "        filtered_t[i, :] = sosfilt(sos, data_t[i, :])\n",
    "    return filtered_t.T\n",
    "\n",
    "def mains_removal(data, fs, notch_freq, quality_factor):\n",
    "    b, a = iirnotch(notch_freq, quality_factor, fs)\n",
    "    data_t = data.T\n",
    "    try:\n",
    "        filtered_t = filtfilt(b, a, data_t, axis=1, method=\"gust\")\n",
    "    except Exception:\n",
    "        filtered_t = filtfilt(b, a, data_t, axis=1)\n",
    "    return filtered_t.T\n",
    "\n",
    "def preprocess_data(data, fs, notch_freq, quality_factor, lowcut, highcut, order, target_fs=None):\n",
    "    notched_data = mains_removal(data, fs=fs, notch_freq=notch_freq, quality_factor=quality_factor)\n",
    "    filtered_data = butter_bandpass_filter(notched_data, lowcut=lowcut, highcut=highcut, fs=fs, order=order)\n",
    "    if target_fs and fs != target_fs:\n",
    "        num_samples = int(data.shape[1] * target_fs / fs)\n",
    "        downsampled_data = resample(filtered_data, num=num_samples, axis=1)\n",
    "        return downsampled_data\n",
    "    return filtered_data\n",
    "\n",
    "def truncate_to_min_length(data1, data2):\n",
    "    min_length = min(data1.shape[1], data2.shape[1])\n",
    "    return data1[:, :min_length], data2[:, :min_length]\n",
    "\n",
    "def window_with_overlap(data, sampling_frequency, window_time, overlap, no_channel):\n",
    "    samples_per_window = int(sampling_frequency * (window_time / 1000))\n",
    "    step_size = int(samples_per_window * (1 - overlap / 100))\n",
    "    step_size = max(step_size, 1)\n",
    "    if data.shape[1] < samples_per_window:\n",
    "        return np.zeros((0, no_channel, samples_per_window), dtype=data.dtype)\n",
    "    num_windows = (data.shape[1] - samples_per_window) // step_size + 1\n",
    "    windows = np.zeros((num_windows, no_channel, samples_per_window), dtype=data.dtype)\n",
    "    for i in range(num_windows):\n",
    "        start = i * step_size\n",
    "        end = start + samples_per_window\n",
    "        windows[i] = data[:, start:end]\n",
    "    return windows\n",
    "\n",
    "# ============================================================\n",
    "# Robust MAT loading (prevents dimension errors)\n",
    "# ============================================================\n",
    "\n",
    "def resolve_mat_root(base_dir: str) -> str:\n",
    "    cand = os.path.join(base_dir, \"mat_data\")\n",
    "    return cand if os.path.isdir(cand) else base_dir\n",
    "\n",
    "EEG_ROOT = resolve_mat_root(EEG_BASE)\n",
    "EMG_ROOT = resolve_mat_root(EMG_BASE)\n",
    "\n",
    "def load_mat_data(filepath: str) -> np.ndarray:\n",
    "    mat = loadmat(filepath)\n",
    "    if \"data\" in mat:\n",
    "        arr = mat[\"data\"]\n",
    "    else:\n",
    "        arr = None\n",
    "        for k, v in mat.items():\n",
    "            if k.startswith(\"__\"):\n",
    "                continue\n",
    "            if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.number):\n",
    "                arr = v\n",
    "                break\n",
    "        if arr is None:\n",
    "            raise ValueError(f\"No numeric data found in {filepath}\")\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    arr = np.squeeze(arr)\n",
    "\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(1, -1)\n",
    "    if arr.ndim != 2:\n",
    "        arr = arr.reshape(arr.shape[0], -1)\n",
    "\n",
    "    if np.iscomplexobj(arr):\n",
    "        arr = np.real(arr)\n",
    "\n",
    "    return arr.astype(np.float64, copy=False)\n",
    "\n",
    "def ensure_channels_by_time(arr: np.ndarray, expected_ch: int, force_fixed: bool) -> np.ndarray:\n",
    "    # prefer exact match in either orientation\n",
    "    if arr.shape[0] == expected_ch:\n",
    "        x = arr\n",
    "    elif arr.shape[1] == expected_ch:\n",
    "        x = arr.T\n",
    "    else:\n",
    "        # heuristic: channels closer to expected\n",
    "        if abs(arr.shape[0] - expected_ch) > abs(arr.shape[1] - expected_ch):\n",
    "            x = arr.T\n",
    "        else:\n",
    "            x = arr\n",
    "\n",
    "    ch, t = x.shape\n",
    "    if ch != expected_ch:\n",
    "        if not force_fixed:\n",
    "            raise ValueError(f\"Channel mismatch: got {ch}, expected {expected_ch}\")\n",
    "        if ch > expected_ch:\n",
    "            x = x[:expected_ch, :]\n",
    "        else:\n",
    "            pad = np.zeros((expected_ch - ch, t), dtype=x.dtype)\n",
    "            x = np.vstack([x, pad])\n",
    "\n",
    "    return x\n",
    "\n",
    "def files_for_subject_gesture(base_path: str, subject_id: int, gesture_idx_1based: int):\n",
    "    subj_dir = os.path.join(base_path, f\"subject_{subject_id}\")\n",
    "    if not os.path.isdir(subj_dir):\n",
    "        return []\n",
    "    all_files = os.listdir(subj_dir)\n",
    "    pat = re.compile(rf\"G{gesture_idx_1based}\", re.IGNORECASE)\n",
    "    return [\n",
    "        os.path.join(subj_dir, f)\n",
    "        for f in all_files\n",
    "        if f.lower().endswith(\".mat\") and pat.search(f)\n",
    "    ]\n",
    "\n",
    "def stack_trials_timewise(file_list, expected_ch: int, force_fixed: bool):\n",
    "    chunks = []\n",
    "    for fp in sorted(file_list):\n",
    "        try:\n",
    "            arr = load_mat_data(fp)\n",
    "            arr = ensure_channels_by_time(arr, expected_ch, force_fixed)\n",
    "            if arr.shape[1] > 0:\n",
    "                chunks.append(arr)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Skipping file: {fp} | reason: {e}\")\n",
    "            continue\n",
    "    if not chunks:\n",
    "        return None\n",
    "    # keeps your original behavior (column_stack concatenates time)\n",
    "    return np.column_stack(chunks)\n",
    "\n",
    "# ============================================================\n",
    "# Optional augmentation (OFF by default)\n",
    "# ============================================================\n",
    "\n",
    "def add_noise(x, noise_level=0.01):\n",
    "    return x + np.random.normal(0, noise_level, size=x.shape)\n",
    "\n",
    "def scale_data(x, scale_factor=1.1):\n",
    "    return x * scale_factor\n",
    "\n",
    "def time_shift(x, shift=5):\n",
    "    return np.roll(x, shift, axis=0)\n",
    "\n",
    "def flip_data(x):\n",
    "    return -x\n",
    "\n",
    "def augment_rows(Xeeg_2d, Xemg_2d, y, subj):\n",
    "    eeg_aug, emg_aug, y_aug, subj_aug = [], [], [], []\n",
    "    for i in range(Xeeg_2d.shape[0]):\n",
    "        e = Xeeg_2d[i]\n",
    "        m = Xemg_2d[i]\n",
    "        lab = int(y[i])\n",
    "        sid = int(subj[i])\n",
    "\n",
    "        eeg_aug.append(e); emg_aug.append(m); y_aug.append(lab); subj_aug.append(sid)\n",
    "        eeg_aug.append(add_noise(e)); emg_aug.append(add_noise(m)); y_aug.append(lab); subj_aug.append(sid)\n",
    "        eeg_aug.append(scale_data(e)); emg_aug.append(scale_data(m)); y_aug.append(lab); subj_aug.append(sid)\n",
    "        eeg_aug.append(time_shift(e, shift=5)); emg_aug.append(time_shift(m, shift=5)); y_aug.append(lab); subj_aug.append(sid)\n",
    "        eeg_aug.append(flip_data(e)); emg_aug.append(flip_data(m)); y_aug.append(lab); subj_aug.append(sid)\n",
    "\n",
    "    return (\n",
    "        np.asarray(eeg_aug, dtype=np.float32),\n",
    "        np.asarray(emg_aug, dtype=np.float32),\n",
    "        np.asarray(y_aug, dtype=np.int64),\n",
    "        np.asarray(subj_aug, dtype=np.int64),\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Sub-1 pipeline\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_subject(subject_id: int):\n",
    "    X_emg_list, X_eeg_list, y_list, subj_list = [], [], [], []\n",
    "    total_windows = 0\n",
    "\n",
    "    for g0 in range(NO_GESTURE):     # labels 0..6\n",
    "        g1 = g0 + 1                  # file pattern G1..G7\n",
    "\n",
    "        emg_files = files_for_subject_gesture(EMG_ROOT, subject_id, g1)\n",
    "        eeg_files = files_for_subject_gesture(EEG_ROOT, subject_id, g1)\n",
    "        if not emg_files or not eeg_files:\n",
    "            continue\n",
    "\n",
    "        emg_raw = stack_trials_timewise(emg_files, EXPECTED_EMG_CH, FORCE_FIXED_CHANNELS)\n",
    "        eeg_raw = stack_trials_timewise(eeg_files, EXPECTED_EEG_CH, FORCE_FIXED_CHANNELS)\n",
    "        if emg_raw is None or eeg_raw is None:\n",
    "            continue\n",
    "\n",
    "        emg_pp = preprocess_data(emg_raw, EMG_FS, NOTCH_FREQ, QUALITY_FACTOR, EMG_FC, EMG_FH, ORDER, TARGET_FS)\n",
    "        eeg_pp = preprocess_data(eeg_raw, EEG_FS, NOTCH_FREQ, QUALITY_FACTOR, EEG_FC, EEG_FH, ORDER, TARGET_FS)\n",
    "\n",
    "        emg_pp, eeg_pp = truncate_to_min_length(emg_pp, eeg_pp)\n",
    "\n",
    "        emg_w = window_with_overlap(emg_pp, TARGET_FS, WINDOW_TIME_MS, OVERLAP_PERCENT, emg_pp.shape[0])\n",
    "        eeg_w = window_with_overlap(eeg_pp, TARGET_FS, WINDOW_TIME_MS, OVERLAP_PERCENT, eeg_pp.shape[0])\n",
    "\n",
    "        if emg_w.shape[0] == 0 or eeg_w.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        n = min(emg_w.shape[0], eeg_w.shape[0])\n",
    "        emg_w = emg_w[:n].astype(np.float32)\n",
    "        eeg_w = eeg_w[:n].astype(np.float32)\n",
    "\n",
    "        X_emg_list.append(emg_w)\n",
    "        X_eeg_list.append(eeg_w)\n",
    "        y_list.extend([g0] * n)\n",
    "        subj_list.extend([subject_id] * n)\n",
    "        total_windows += n\n",
    "\n",
    "    if not X_emg_list or not X_eeg_list:\n",
    "        raise RuntimeError(f\"No windows produced for subject_{subject_id}. Check folder/files.\")\n",
    "\n",
    "    X_emg = np.vstack(X_emg_list)  # (N, 8, T)\n",
    "    X_eeg = np.vstack(X_eeg_list)  # (N, 8, T)\n",
    "    y = np.asarray(y_list, dtype=np.int64)\n",
    "    subj = np.asarray(subj_list, dtype=np.int64)\n",
    "\n",
    "    # safety\n",
    "    n = min(len(y), X_emg.shape[0], X_eeg.shape[0], len(subj))\n",
    "    return X_emg[:n], X_eeg[:n], y[:n], subj[:n], total_windows\n",
    "\n",
    "def export_subject_csvs(X_emg, X_eeg, y, subj):\n",
    "    Xeeg_2d = X_eeg.reshape(X_eeg.shape[0], -1)\n",
    "    Xemg_2d = X_emg.reshape(X_emg.shape[0], -1)\n",
    "\n",
    "    eeg_scaler = MinMaxScaler()\n",
    "    emg_scaler = MinMaxScaler()\n",
    "    Xeeg_norm = eeg_scaler.fit_transform(Xeeg_2d).astype(np.float32)\n",
    "    Xemg_norm = emg_scaler.fit_transform(Xemg_2d).astype(np.float32)\n",
    "\n",
    "    if DO_AUGMENT:\n",
    "        Xeeg_final, Xemg_final, y_final, subj_final = augment_rows(Xeeg_norm, Xemg_norm, y, subj)\n",
    "    else:\n",
    "        Xeeg_final, Xemg_final, y_final, subj_final = Xeeg_norm, Xemg_norm, y, subj\n",
    "\n",
    "    eeg_path = os.path.join(OUT_DIR, \"eeg_sub1.csv\")\n",
    "    emg_path = os.path.join(OUT_DIR, \"emg_sub1.csv\")\n",
    "    lab_path = os.path.join(OUT_DIR, \"labels_sub1.csv\")\n",
    "    comb_path = os.path.join(OUT_DIR, \"combined_sub1.csv\")\n",
    "\n",
    "    pd.DataFrame(Xeeg_final).to_csv(eeg_path, index=False)\n",
    "    pd.DataFrame(Xemg_final).to_csv(emg_path, index=False)\n",
    "    pd.DataFrame({\"subject_id\": subj_final, \"Label\": y_final}).to_csv(lab_path, index=False)\n",
    "\n",
    "    eeg_cols = [f\"eeg_{i}\" for i in range(Xeeg_final.shape[1])]\n",
    "    emg_cols = [f\"emg_{i}\" for i in range(Xemg_final.shape[1])]\n",
    "\n",
    "    df_eeg = pd.DataFrame(Xeeg_final, columns=eeg_cols)\n",
    "    df_emg = pd.DataFrame(Xemg_final, columns=emg_cols)\n",
    "\n",
    "    df_eeg.insert(0, \"Label\", y_final)\n",
    "    df_eeg.insert(0, \"subject_id\", subj_final)\n",
    "    df_comb = pd.concat([df_eeg, df_emg], axis=1)\n",
    "    df_comb.to_csv(comb_path, index=False)\n",
    "\n",
    "    print(\"\\n[SAVED SUB-1]\")\n",
    "    print(\" \", eeg_path)\n",
    "    print(\" \", emg_path)\n",
    "    print(\" \", lab_path)\n",
    "    print(\" \", comb_path)\n",
    "    print(f\"\\nRows: {len(y_final)} | label set: {np.unique(y_final)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_emg, X_eeg, y, subj, total = preprocess_subject(SUBJECT_ID)\n",
    "    print(f\"[OK] subject_{SUBJECT_ID}: windows={total}\")\n",
    "    export_subject_csvs(X_emg, X_eeg, y, subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db894858-180e-402c-b404-dd08024b3ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
