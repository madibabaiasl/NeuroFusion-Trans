{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c6329-cc54-4ef1-998e-6a7e510c6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score,\n",
    "    confusion_matrix, balanced_accuracy_score, cohen_kappa_score,\n",
    "    matthews_corrcoef, log_loss\n",
    ")\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "DATA_ROOT = Path(\"/home/tsultan1/paper-2/Dataset-2\")\n",
    "\n",
    "SUB_DIR_PATTERN = re.compile(r\"final_exports-sub(\\d+)$\")\n",
    "\n",
    "# Output folder for best model\n",
    "OUT_DIR = DATA_ROOT / \"train_all_subjects_outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training\n",
    "K_FOLDS = 5\n",
    "EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 256\n",
    "LR = 5e-4\n",
    "WEIGHT_DECAY = 1e-2\n",
    "\n",
    "# Optional online adaptation\n",
    "DO_ONLINE_ADAPT = True\n",
    "ONLINE_ADAPT_FRAC = 0.30\n",
    "ONLINE_CYCLES = 5\n",
    "ONLINE_BS = 128\n",
    "ONLINE_LR = 1e-5\n",
    "REPLAY_N = 100\n",
    "\n",
    "# GPU speed\n",
    "USE_AMP = True\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SEED\n",
    "# ============================================================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def read_numeric_csv(path: Path) -> np.ndarray:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "    return df.to_numpy(dtype=np.float32)\n",
    "\n",
    "def load_labels_csv(lbl_path: Path, sid: int):\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - columns: Label\n",
    "      - columns: subject_id, Label\n",
    "      - lowercase variants\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(lbl_path)\n",
    "\n",
    "    # normalize column names\n",
    "    cols = {c: c.strip() for c in df.columns}\n",
    "    df.rename(columns=cols, inplace=True)\n",
    "\n",
    "    # find Label column\n",
    "    label_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() == \"label\":\n",
    "            label_col = c\n",
    "            break\n",
    "    if label_col is None:\n",
    "        raise ValueError(f\"{lbl_path} missing 'Label' column\")\n",
    "\n",
    "    y = df[label_col].astype(np.int64).to_numpy()\n",
    "\n",
    "    # subject_id optional\n",
    "    subj_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() == \"subject_id\":\n",
    "            subj_col = c\n",
    "            break\n",
    "    if subj_col is None:\n",
    "        sid_arr = np.full(len(y), sid, dtype=np.int64)\n",
    "    else:\n",
    "        sid_arr = df[subj_col].astype(np.int64).to_numpy()\n",
    "\n",
    "    return y, sid_arr\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATA LOADING (per subject folder: eeg_sub{sid}.csv etc.)\n",
    "# ============================================================\n",
    "\n",
    "def subject_id_from_folder(folder: Path) -> int:\n",
    "    m = SUB_DIR_PATTERN.match(folder.name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Folder does not match pattern final_exports-subX: {folder}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "def find_subject_files(sub_dir: Path, sid: int):\n",
    "    \"\"\"\n",
    "    Your true filenames:\n",
    "      eeg_sub{sid}.csv, emg_sub{sid}.csv, labels_sub{sid}.csv\n",
    "    Also supports fallback to *_final.csv if present.\n",
    "    \"\"\"\n",
    "    eeg_candidates = [\n",
    "        sub_dir / f\"eeg_sub{sid}.csv\",\n",
    "        sub_dir / \"eeg_final.csv\",\n",
    "    ]\n",
    "    emg_candidates = [\n",
    "        sub_dir / f\"emg_sub{sid}.csv\",\n",
    "        sub_dir / \"emg_final.csv\",\n",
    "    ]\n",
    "    lbl_candidates = [\n",
    "        sub_dir / f\"labels_sub{sid}.csv\",\n",
    "        sub_dir / \"labels_final.csv\",\n",
    "    ]\n",
    "\n",
    "    eeg_path = next((p for p in eeg_candidates if p.exists()), None)\n",
    "    emg_path = next((p for p in emg_candidates if p.exists()), None)\n",
    "    lbl_path = next((p for p in lbl_candidates if p.exists()), None)\n",
    "\n",
    "    return eeg_path, emg_path, lbl_path\n",
    "\n",
    "def load_one_subject_folder(sub_dir: Path):\n",
    "    sid = subject_id_from_folder(sub_dir)\n",
    "    eeg_path, emg_path, lbl_path = find_subject_files(sub_dir, sid)\n",
    "\n",
    "    if eeg_path is None or emg_path is None or lbl_path is None:\n",
    "        return None\n",
    "\n",
    "    eeg = read_numeric_csv(eeg_path)\n",
    "    emg = read_numeric_csv(emg_path)\n",
    "    y, sid_arr = load_labels_csv(lbl_path, sid)\n",
    "\n",
    "    # align lengths\n",
    "    n = min(len(y), eeg.shape[0], emg.shape[0], len(sid_arr))\n",
    "    if n <= 0:\n",
    "        return None\n",
    "\n",
    "    eeg = eeg[:n]\n",
    "    emg = emg[:n]\n",
    "    y = y[:n]\n",
    "    sid_arr = sid_arr[:n]\n",
    "\n",
    "    # combine features\n",
    "    X = np.concatenate([eeg, emg], axis=1)  # (N, Feeg+Femg)\n",
    "    input_dim = eeg.shape[1]                # split point\n",
    "    return X, y, sid_arr, input_dim\n",
    "\n",
    "def load_all_subjects_combined(data_root: Path):\n",
    "    subdirs = [p for p in data_root.iterdir() if p.is_dir() and SUB_DIR_PATTERN.match(p.name)]\n",
    "    subdirs = sorted(subdirs, key=lambda p: subject_id_from_folder(p))\n",
    "\n",
    "    if not subdirs:\n",
    "        raise RuntimeError(f\"No folders found like final_exports-subX under {data_root}\")\n",
    "\n",
    "    X_all, y_all, sid_all = [], [], []\n",
    "    input_dim_ref = None\n",
    "    total_dim_ref = None\n",
    "\n",
    "    for sd in subdirs:\n",
    "        try:\n",
    "            out = load_one_subject_folder(sd)\n",
    "            if out is None:\n",
    "                print(f\"[SKIP] {sd.name}: missing files or empty\")\n",
    "                continue\n",
    "\n",
    "            X, y, sid_arr, input_dim = out\n",
    "\n",
    "            if input_dim_ref is None:\n",
    "                input_dim_ref = input_dim\n",
    "                total_dim_ref = X.shape[1]\n",
    "            else:\n",
    "                if input_dim != input_dim_ref or X.shape[1] != total_dim_ref:\n",
    "                    warnings.warn(\n",
    "                        f\"Skipping {sd.name}: feature mismatch \"\n",
    "                        f\"(got input_dim={input_dim}, total={X.shape[1]} vs \"\n",
    "                        f\"ref input_dim={input_dim_ref}, total={total_dim_ref})\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            X_all.append(X)\n",
    "            y_all.append(y)\n",
    "            sid_all.append(sid_arr)\n",
    "\n",
    "            print(f\"[OK] {sd.name}: N={len(y)} | X={X.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"[SKIP] {sd.name}: {e}\")\n",
    "\n",
    "    if not X_all:\n",
    "        raise RuntimeError(\"No subject data loaded. Check file names and folder structure.\")\n",
    "\n",
    "    X = np.vstack(X_all)\n",
    "    y = np.concatenate(y_all)\n",
    "    sid = np.concatenate(sid_all)\n",
    "\n",
    "    return X, y, sid, input_dim_ref\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATASET\n",
    "# ============================================================\n",
    "\n",
    "class EEGEMGDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL\n",
    "# ============================================================\n",
    "\n",
    "class EEGEMGTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.align_eeg = nn.Linear(input_dim, input_dim)\n",
    "        self.align_emg = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        self.eeg_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True, dropout=dropout_rate),\n",
    "            num_layers=2\n",
    "        )\n",
    "        self.emg_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True, dropout=dropout_rate),\n",
    "            num_layers=2\n",
    "        )\n",
    "\n",
    "        self.eeg_projector = nn.Linear(input_dim, hidden_dim)\n",
    "        self.emg_projector = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.cross_attention_weights = nn.Parameter(\n",
    "            torch.tensor([[0.7], [0.3]], dtype=torch.float32), requires_grad=True\n",
    "        )\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, eeg, emg):\n",
    "        eeg = self.align_eeg(eeg)\n",
    "        emg = self.align_emg(emg)\n",
    "\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "\n",
    "        eeg_features = self.dropout(self.eeg_projector(eeg_features))\n",
    "        emg_features = self.dropout(self.emg_projector(emg_features))\n",
    "\n",
    "        combined = (\n",
    "            self.cross_attention_weights[0] * eeg_features +\n",
    "            self.cross_attention_weights[1] * emg_features\n",
    "        )\n",
    "\n",
    "        combined, _ = self.cross_attention(combined, combined, combined)\n",
    "        out = self.fc(combined.mean(dim=1))\n",
    "        return out, self.cross_attention_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, device, input_dim,\n",
    "                epochs=50, patience=5, lr=5e-4, weight_decay=1e-2, use_amp=True):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    bad = 0\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            eeg = Xb[:, :input_dim].unsqueeze(1)\n",
    "            emg = Xb[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                logits, _ = model(eeg, emg)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_loss += float(loss.detach().cpu())\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "                eeg = Xb[:, :input_dim].unsqueeze(1)\n",
    "                emg = Xb[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                    logits, _ = model(eeg, emg)\n",
    "                    loss = criterion(logits, yb)\n",
    "\n",
    "                va_loss += float(loss.detach().cpu())\n",
    "\n",
    "        tr_loss /= max(1, len(train_loader))\n",
    "        va_loss /= max(1, len(val_loader))\n",
    "        print(f\"Epoch {ep+1}/{epochs} | train={tr_loss:.4f} | val={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_loss:\n",
    "            best_loss = va_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONLINE ADAPT\n",
    "# ============================================================\n",
    "\n",
    "def online_adapt(model, buffer_X, buffer_y, replay_X, replay_y, criterion,\n",
    "                 val_loader, device, input_dim, num_cycles=5, batch_size=128, lr=1e-5, use_amp=True):\n",
    "\n",
    "    if replay_X is not None and len(replay_X) > 0:\n",
    "        buffer_X = np.concatenate([buffer_X, replay_X], axis=0)\n",
    "        buffer_y = np.concatenate([buffer_y, replay_y], axis=0)\n",
    "\n",
    "    ds = EEGEMGDataset(buffer_X, buffer_y)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=lr/10, max_lr=lr, step_size_up=5, mode=\"triangular2\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    for c in range(num_cycles):\n",
    "        print(f\"Online cycle {c+1}/{num_cycles}\")\n",
    "\n",
    "        model.train()\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            eeg = Xb[:, :input_dim].unsqueeze(1)\n",
    "            emg = Xb[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                logits, _ = model(eeg, emg)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "        # val check\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "                eeg = Xb[:, :input_dim].unsqueeze(1)\n",
    "                emg = Xb[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                    logits, _ = model(eeg, emg)\n",
    "                    loss = criterion(logits, yb)\n",
    "\n",
    "                val_loss += float(loss.detach().cpu())\n",
    "\n",
    "        val_loss /= max(1, len(val_loader))\n",
    "        print(f\"  val_loss={val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            print(\"  early stop online adapt\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EVAL (NO PLOTS)\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_no_plots(model, loader, num_classes, device, input_dim):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_scores = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            eeg = Xb[:, :input_dim].unsqueeze(1)\n",
    "            emg = Xb[:, input_dim:].unsqueeze(1)\n",
    "\n",
    "            logits, _ = model(eeg, emg)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "            y_true.extend(yb.cpu().numpy().tolist())\n",
    "            y_pred.extend(pred.cpu().numpy().tolist())\n",
    "            y_scores.extend(probs.cpu().numpy().tolist())\n",
    "\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.int64)\n",
    "    y_scores = np.asarray(y_scores, dtype=np.float64)\n",
    "\n",
    "    labels_all = np.arange(num_classes, dtype=np.int64)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    ll = log_loss(y_true, y_scores, labels=labels_all)\n",
    "    top3 = top_k_accuracy_score(y_true, y_scores, k=min(3, num_classes), labels=labels_all)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels_all)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        per_class_acc = np.diag(cm) / np.maximum(1, cm.sum(axis=1))\n",
    "    mpce = float(np.mean(1.0 - per_class_acc))\n",
    "\n",
    "    auroc = None\n",
    "    auprc = None\n",
    "    try:\n",
    "        Yb = label_binarize(y_true, classes=labels_all)\n",
    "        auroc = roc_auc_score(Yb, y_scores, average=\"weighted\")\n",
    "        auprc = average_precision_score(Yb, y_scores, average=\"weighted\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"Prec={precision:.3f} Rec={recall:.3f} F1={f1:.3f} Acc={acc:.3f} BalAcc={bal_acc:.3f}\")\n",
    "    print(f\"Kappa={kappa:.3f} MCC={mcc:.3f} LogLoss={ll:.4f} Top3={top3:.4f} MPCE={mpce:.4f}\")\n",
    "    if auroc is not None:\n",
    "        print(f\"AUROC={auroc:.4f} AUPRC={auprc:.4f}\")\n",
    "\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"[INFO] CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    # Load ALL subjects\n",
    "    X, y, sid, input_dim = load_all_subjects_combined(DATA_ROOT)\n",
    "    num_classes = int(np.max(y)) + 1\n",
    "\n",
    "    print(f\"[INFO] X={X.shape} y={y.shape} input_dim={input_dim} classes={num_classes}\")\n",
    "    print(f\"[INFO] label counts: {np.bincount(y)}\")\n",
    "    print(f\"[SANITY] mean(feature variance)={np.var(X, axis=0).mean():.6f}\")\n",
    "\n",
    "    # KFold (not LOSO)\n",
    "    kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_state = None\n",
    "    best_fold = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
    "        print(f\"\\n===== Fold {fold}/{K_FOLDS} =====\")\n",
    "        X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        train_ds = EEGEMGDataset(X_tr, y_tr)\n",
    "        val_ds = EEGEMGDataset(X_va, y_va)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "        model = EEGEMGTransformer(input_dim=input_dim, hidden_dim=256, num_heads=4, num_classes=num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        model = train_model(model, train_loader, val_loader, criterion, device, input_dim, EPOCHS, PATIENCE, LR, WEIGHT_DECAY, USE_AMP)\n",
    "\n",
    "        print(\"Before online adapt:\")\n",
    "        _ = evaluate_no_plots(model, val_loader, num_classes, device, input_dim)\n",
    "\n",
    "        if DO_ONLINE_ADAPT:\n",
    "            online_n = int(len(X_va) * ONLINE_ADAPT_FRAC)\n",
    "            replay_n = min(REPLAY_N, len(X_tr))\n",
    "            model = online_adapt(\n",
    "                model,\n",
    "                buffer_X=X_va[:online_n], buffer_y=y_va[:online_n],\n",
    "                replay_X=X_tr[:replay_n], replay_y=y_tr[:replay_n],\n",
    "                criterion=criterion,\n",
    "                val_loader=val_loader,\n",
    "                device=device,\n",
    "                input_dim=input_dim,\n",
    "                num_cycles=ONLINE_CYCLES,\n",
    "                batch_size=ONLINE_BS,\n",
    "                lr=ONLINE_LR,\n",
    "                use_amp=USE_AMP\n",
    "            )\n",
    "\n",
    "        print(\"After online adapt:\")\n",
    "        met = evaluate_no_plots(model, val_loader, num_classes, device, input_dim)\n",
    "\n",
    "        if met[\"accuracy\"] > best_acc:\n",
    "            best_acc = met[\"accuracy\"]\n",
    "            best_fold = fold\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    out_path = OUT_DIR / \"EEGEMGTransformer_best_allsubjects.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"state_dict\": best_state,\n",
    "            \"input_dim\": input_dim,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"best_fold\": best_fold,\n",
    "            \"label_set\": np.unique(y).tolist(),\n",
    "            \"seed\": SEED,\n",
    "        },\n",
    "        out_path\n",
    "    )\n",
    "    print(f\"\\n[OK] Saved: {out_path} | best_fold={best_fold} | acc={best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f2257-0f38-4d4f-93c4-040139a9933e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4419560-8b44-4848-a059-d26a4ceceba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
